{"organizations": [], "uuid": "a3d6c9bb8ec756f93e924a6d0549e8e6638fa126", "thread": {"social": {"gplus": {"shares": 2}, "pinterest": {"shares": 3}, "vk": {"shares": 0}, "linkedin": {"shares": 18}, "facebook": {"likes": 204, "shares": 204, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "nymag.com", "main_image": "http://pixel.nymag.com/imgs/daily/selectall/2017/02/21/21-elon-musk.w1200.h630.jpg", "site_section": "http://nymag.com/", "section_title": "NYMag - Politics, Entertainment, Fashion, Restaurants &amp; NY", "url": "http://nymag.com/selectall/2017/02/the-magical-rationalism-of-elon-musk-and-the-prophets-of-ai.html", "country": "US", "domain_rank": 1627, "title": "The Magical Rationalism of Elon Musk and the Prophets of AI", "performance_score": 2, "site": "nymag.com", "participants_count": 1, "title_full": "The Magical Rationalism of Elon Musk and the Prophets of AI", "spam_score": 0.0, "site_type": "news", "published": "2017-02-21T21:58:00.000+02:00", "replies_count": 0, "uuid": "a3d6c9bb8ec756f93e924a6d0549e8e6638fa126"}, "author": "", "url": "http://nymag.com/selectall/2017/02/the-magical-rationalism-of-elon-musk-and-the-prophets-of-ai.html", "ord_in_thread": 0, "title": "The Magical Rationalism of Elon Musk and the Prophets of AI", "locations": [], "entities": {"persons": [{"name": "elon musk", "sentiment": "negative"}, {"name": "justin chin/bloomberg", "sentiment": "negative"}, {"name": "musk", "sentiment": "none"}, {"name": "flann o’brien", "sentiment": "none"}, {"name": "milo yiannopoulos resigns from breitbart", "sentiment": "none"}, {"name": "howbow dah", "sentiment": "none"}, {"name": "donald trump", "sentiment": "none"}, {"name": "gordon ramsay", "sentiment": "none"}, {"name": "nate soares", "sentiment": "none"}, {"name": "o’brien", "sentiment": "none"}, {"name": "eric holder", "sentiment": "none"}, {"name": "dylan milo yiannopoulos resigns from breitbart", "sentiment": "none"}, {"name": "dylan dylan", "sentiment": "none"}, {"name": "jason segel", "sentiment": "none"}, {"name": "travis kalanick", "sentiment": "none"}, {"name": "ray kurzweil", "sentiment": "none"}, {"name": "susan fowler", "sentiment": "none"}], "locations": [{"name": "united states", "sentiment": "none"}, {"name": "silicon valley", "sentiment": "none"}, {"name": "berkeley", "sentiment": "none"}, {"name": "dubai", "sentiment": "none"}, {"name": "russia", "sentiment": "none"}, {"name": "horizon zero dawn", "sentiment": "none"}, {"name": "elon musk", "sentiment": "none"}], "organizations": [{"name": "wall street journal", "sentiment": "none"}, {"name": "facebook tweet", "sentiment": "none"}, {"name": "miri (machine intelligence research institute", "sentiment": "none"}, {"name": "new facebook manifesto zuck", "sentiment": "none"}, {"name": "uber employees to conduct ‘independent review", "sentiment": "none"}, {"name": "google", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "Photo: Justin Chin/Bloomberg via Getty Images One morning in the summer of 2015, I sat in a featureless office in Berkeley as a young computer programmer walked me through how he intended to save the world. The world needed saving, he insisted, not from climate change — or from the rise of the far right, or the treacherous instability of global capitalism — but from the advent of artificial superintelligence, which would almost certainly wipe humanity from the face of the earth unless certain preventative measures were put in place by a very small number of dedicated specialists such as himself, who alone understood the scale of the danger and the course of action necessary to protect against it.\nThis intense and deeply serious young programmer was Nate Soares, the executive director of MIRI (Machine Intelligence Research Institute), a nonprofit organization dedicated to the safe — which is to say, non-humanity-obliterating — development of artificial intelligence. As I listened to him speak, and as I struggled (and failed) to follow the algebraic abstractions he was scrawling on a whiteboard in illustration of his preferred doomsday scenario, I was suddenly hit by the full force of a paradox: The austere and inflexible rationalism of this man’s worldview had led him into a grand and methodically reasoned absurdity.\nIn researching and reporting my book, To Be a Machine , I had spent much of the previous 18 months among the adherents of the transhumanist movement, a broad church comprising life-extension advocates, cryonicists, would-be cyborgs, Silicon Valley tech entrepreneurs, neuroscientists looking to convert the human brain into code, and so forth — all of whom were entirely convinced that science and technology would allow us to transcend the human condition. With many of these transhumanists (the vast majority of whom, it bears mentioning, were men), I had experienced some version of this weird cognitive dissonance, this apprehension of a logic-unto-madness. I had come across it so frequently, in fact, that I wound up giving it a name: magical rationalism.\nThe key thing about magical rationalism is that its approach to a given question always seems, and in most meaningful respects is , perfectly logical. To take our current example, the argument about AI posing an existential risk to our species seems, on one level, quite compelling. The basic gist is this: If and when we develop human-level artificial intelligence, it’s only a matter of time until this AI, by creating smarter and smarter iterations of itself, gives rise to a machine whose intelligence is as superior to our own as our intelligence currently is to that of other animal species. (Let’s leave the cephalopods out of this for the moment, because who knows what the hell is going on with those guys.) Computers being what they are, though, there’s a nontrivial risk of this superintelligent AI taking the commands it’s issued far too literally. You tell it, for instance, to eliminate cancer once and for all, and it takes the shortest and most logical route to that end by wiping out all life-forms in which abnormal cell division might potentially occur. (An example of the cure-worse-than-the-disease scenario so perfect that you would not survive long enough to appreciate its perfection.) As far as I can see, there’s nothing about this scenario that is anything but logically sound, and yet here we are, taken to a place that most of us will agree feels deeply and intuitively batshit. (The obvious counterargument to this, of course, is that just because something feels intuitively batshit doesn’t mean that it’s not going to happen. It’s worth bearing in mind that the history of science is replete with examples of this principle.)\nMagical rationalism arises out of a quasi-religious worldview, in which reason takes the place of the godhead, and whereby all of our human problems are soluble by means of its application. The power of rationalism, manifested in the form of technology — the word made silicon — has the potential to deliver us from all evils, up to and including death itself. This spiritual dimension is most clearly visible in the techno-millenarianism of the Singularity: the point on the near horizon of our future at which human beings will finally and irrevocably merge with technology, to become uploaded minds, disembodied beings of pure and immutable thought. (Nate Soares, in common with many of those working to eliminate the existential threat posed by AI, viewed this as the best-case scenario for the future, as the kingdom of heaven that would be ours if we could only avoid the annihilation of our species by AI. I myself found it hard to conceive of as anything other than a vision of deepest hell.)\nIn his book The Singularity is Near , Ray Kurzweil, a futurist and director of engineering at Google, lays out the specifics of this post-human afterlife. “The Singularity,” he writes, “will allow us to transcend these limitations of our biological bodies and brains. We will gain power over our fates. Our mortality will be in our hands. We will be able to live as long as we want (a subtly different statement from saying we will live forever). We will fully understand human thinking and will vastly extend and expand its reach. By the end of this century, the nonbiological portion of our intelligence will be trillions of times more powerful than unaided human intelligence.” This is magical rationalism in its purest form: It arises out of the same human terrors and desires as the major religions — the terror of death, the desire to transcend it — and proceeds toward the same kinds of visionary mythologizing.\nThis particular Singularitarian strain of magical rationalism could be glimpsed in Elon Musk’s widely reported recent comments at a conference in Dubai. Humans, he insisted, would need to merge with machines in order to avoid becoming obsolete. “It’s mostly about the bandwidth,” he explained; computers were capable of processing information at a trillion bits per second, while we humans could input data into our devices at a mere ten bits per second, or thereabouts. From the point of view of narrow rationalism, Musk’s argument was sort of compelling — if computers are going to beat us at our own game, we’d better find ways to join them — but it only really made sense if you thought of a human being as a kind of computer to begin with. (We’re computers; we’re just rubbish at computing compared to actual computers these days.)\nWhile writing To Be a Machine , I kept finding myself thinking about Flann O’Brien’s surreal comic masterpiece The Third Policeman, in which everyone is unhealthily obsessed with bicycles, and men who spend too much time on their bicycles wind up themselves becoming bicycles via some kind of mysterious process of molecular transfer. Transhumanism — a world as overwhelmingly male as O’Brien’s rural Irish hellscape — often seemed to me to be guided by a similar kind of overidentification with computers, a strange confusion of the distinct categories of human and machine. Because if computation is the ultimate value, the ultimate end of intelligence, then it makes absolute sense to become better versions of the computers we already are. We must “optimize for intelligence,” as transhumanists are fond of saying — meaning by intelligence, in most cases, the exercise of pure reason. And this is the crux of magical rationalism: It is both an idealization of reason, of beautiful and rigorous abstraction, and a mode of thinking whereby reason is made to serve as the faithful handmaiden of absolute madness. Because reason is, among its other uses, a finely calibrated tool by which the human animal pursues its famously unreasonable ends.\nTags: transhumanism elon musk magical rationalism The Magical Rationalism of Elon Musk and the Prophets of AI Share on Facebook Tweet this Story Top Stories YouTube’s Best Vlogger Is This 10-Year-Old Communist Named Dylan Milo Yiannopoulos Resigns From Breitbart WATCH: Flying Drone Taxis Are Real and They’re Spectacular Most Viewed Stories A Conversation With YouTube’s Favorite 10-Year-Old Communist Vlogger A Brief History of ‘Cash Me Outside, Howbow Dah?’ Milo Yiannopoulos Resigns From Breitbart The Magical Rationalism of Elon Musk and the Prophets of AI Gender Discrimination at Uber Is a Reminder of How Hard Women Have to Fight to Be Believed Most Popular Video On Select All This Vintage-Style Instant Camera Is Made Out of Cardboard Latest News from Select All Yesterday at 5:31 p.m. YouTube’s Best Vlogger Is This 10-Year-Old Communist Named Dylan Dylan is in fourth grade and believes communism is the future of the United States.\nYesterday at 4:57 p.m. Milo Yiannopoulos Resigns From Breitbart The controversy-courting figure nets another loss.\nYesterday at 4:37 p.m. WATCH: Flying Drone Taxis Are Real and They’re Spectacular Uber with wings.\nYesterday at 2:58 p.m. Discrimination at Uber Is a Reminder of How Hard Women Must Fight to Be Believed Ex-employee Susan Fowler documented everything during her time at the company, but management still found ways to deny her claims.\nYesterday at 1:58 p.m. The Magical Rationalism of Elon Musk and the Prophets of AI When austere and inflexible rationalism leads into a grand and methodically reasoned absurdity.\nYesterday at 12:23 p.m. Horizon Zero Dawn: The Beautiful Dead End of Open-World Games Hunting down mechanical dinosaurs with a bow and arrow looks and feels great. So why is it such a chore to finish?\nYesterday at 11:43 a.m. Shooting Stars Is the First Big Post-Vine Video Meme A trippy new video meme shoots across the web.\nYesterday at 12:23 a.m. Eric Holder, Uber Employees to Conduct ‘Independent Review’ of Sexism Claims The company is moving fast following harassment allegations from a former employee.\n2/20/2017 at 10:56 a.m. Amateur Chefs Are Asking Gordon Ramsay to Roast Them On Twitter It’s rubbish!\n2/20/2017 at 8:00 a.m. You Can Finally Buy Snapchat Spectacles Online No more tracking down a mysterious vending machine.\n2/20/2017 at 1:03 a.m. Former Uber Engineer Describes ‘Horrifying’ Culture of Sexual Harassment CEO Travis Kalanick promised to “conduct an urgent investigation” and fire anyone who “behaves this way or thinks this is okay.”\n2/17/2017 at 3:37 p.m. Give This Dramatic Rat-Removal Video an Oscar Several young women, one rat, and an incredible plot twist.\n2/17/2017 at 3:30 p.m. Brave Raccoon Goes on Small Adventure to the City Raccoon’s day off.\n2/17/2017 at 2:30 p.m. Dude Vows to Eat Picture of Jason Segel’s Face Daily Until Segel Eats One of His Today marks day one.\n2/17/2017 at 1:17 p.m. YouTube to Ditch Its Longest Unskippable Ads No more waiting half a minute to get to your content.\n2/17/2017 at 12:33 p.m. Why Mark Zuckerberg Just Wrote a New Facebook Manifesto Zuck finally grapples with the power of his creation.\n2/17/2017 at 11:16 a.m. This Donald Trump Tweet Sure Is … Something So many white dudes. So little time.\n2/17/2017 at 10:05 a.m. I Hate This Blob With Arms Meme So Very Much The blob has suddenly become very popular among meme connoisseurs in Russia.\n2/16/2017 at 4:17 p.m. PewDiePie Apologizes for Anti-Semitic Jokes … and Then Blames the Media The YouTube star lashed out at The Wall Street Journal .\n2/16/2017 at 4:03 p.m. Enjoy This Growing Spreadsheet of Texts People Wish They Could Send Their Exes “I should have hit you harder with my car.”", "external_links": ["http://www.facebook.com/sharer/sharer.php?u=http://nymag.com/selectall/2017/02/the-magical-rationalism-of-elon-musk-and-the-prophets-of-ai.html%3Fmid%3Dfb-share-selectall", "http://www.amazon.com/exec/obidos/ASIN/0385540418", "https://twitter.com/share?text=The%20Magical%20Rationalism%20of%20Elon%20Musk%20and%20the%20Prophets%20of%20AI&url=http://nymag.com/selectall/2017/02/the-magical-rationalism-of-elon-musk-and-the-prophets-of-ai.html%3Fmid%3Dtwitter-share-selectall&via=selectall"], "published": "2017-02-21T21:58:00.000+02:00", "crawled": "2017-02-22T10:00:44.569+02:00", "highlightTitle": ""}