{"organizations": [], "uuid": "a34d0dd5ec6d8dc64f245587334727e1774a2d91", "thread": {"social": {"gplus": {"shares": 14}, "pinterest": {"shares": 1}, "vk": {"shares": 0}, "linkedin": {"shares": 57}, "facebook": {"likes": 954, "shares": 954, "comments": 143}, "stumbledupon": {"shares": 0}}, "site_full": "thenextweb.com", "main_image": "https://cdn2.tnwcdn.com/wp-content/blogs.dir/1/files/2017/02/GitLabFeat.png", "site_section": "", "section_title": "", "url": "https://thenextweb.com/dd/2017/02/01/gitlab-offline-catastrophic-database-error-loses-mountains-data/", "country": "US", "domain_rank": 1761, "title": "GitLab offline after catastrophic database error loses mountains of data", "performance_score": 9, "site": "thenextweb.com", "participants_count": 0, "title_full": "GitLab offline after catastrophic database error loses mountains of data", "spam_score": 0.001, "site_type": "news", "published": "2017-02-01T19:09:00.000+02:00", "replies_count": 0, "uuid": "a34d0dd5ec6d8dc64f245587334727e1774a2d91"}, "author": "Matthew Hughes", "url": "https://thenextweb.com/dd/2017/02/01/gitlab-offline-catastrophic-database-error-loses-mountains-data/", "ord_in_thread": 0, "title": "GitLab offline after catastrophic database error loses mountains of data", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "\nYesterday, GitLab announced that it was doing some emergency database maintenance. Unfortunately, it didn’t go to plan. We are performing emergency database maintenance, https://t.co/r11UmmDLDE will be taken offline \n— GitLab.com Status (@gitlabstatus) January 31, 2017 we are experiencing issues with our production database and are working to recover \n— GitLab.com Status (@gitlabstatus) February 1, 2017 We accidentally deleted production data and might have to restore from backup. Google Doc with live notes https://t.co/EVRbHzYlk8 \n— GitLab.com Status (@gitlabstatus) February 1, 2017 \nWhoops. \nGitLab was quick to assure customers that no Git commits had been lost. Just things like merge requests and issue posts. Although given the often detailed nature of issue notifications, and the fact that people generally write them through the web browser instead of through, say, Microsoft Word where they can save an independent copy, this is just as bad. \nRight now, GitLab is trying to restore from their backups. Given the size of its database, this is a long process. We are 60% done with the database copy \n— GitLab.com Status (@gitlabstatus) February 1, 2017 \nSnapshots are taken every 24 hours, and the data loss occurred six hours after the last one was taken. As a result, six hours of data has been lost, perhaps permanently. Predictably, a lot of people are frustrated. @gitlabstatus Come on guys! What's the ETA? \n— Consigliere (@clthck) February 1, 2017 \nThe outage has also meant that the site remains offline, preventing developers from using one of their crucial tools during the middle of the workweek. \nWhile it’ll be easy to be condemnatory of GitLab, it’s worth commending them on their radical transparency. Throughout the process, users have been kept aware of progress via its GitLab Status Twitter account . It was also honest about the cause of the data loss – human error – and didn’t try to pin it on a hardware failure, or an external attacker. GitLab is also livestreaming the recovery efforts, which is certainly novel. \nThis is a developing story. We’ll keep you informed with any new updates. Share on Twitter (11) Matthew Hughes is a reporter from Liverpool. Happy to hear your thoughts on or @matthewhughes on Twitter. Matthew Hughes is a journalist from Liverpool, England. His interests include security, startups, food, and storytelling. Follow him on Twitter . Contact ", "external_links": [], "published": "2017-02-01T19:09:00.000+02:00", "crawled": "2017-02-01T14:11:44.240+02:00", "highlightTitle": ""}