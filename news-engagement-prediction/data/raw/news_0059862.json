{"organizations": [], "uuid": "55978df7fe85d4e8aa2e392cc2154f259c26abc9", "thread": {"social": {"gplus": {"shares": 11}, "pinterest": {"shares": 1}, "vk": {"shares": 0}, "linkedin": {"shares": 109}, "facebook": {"likes": 229, "shares": 229, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.nytimes.com", "main_image": "https://static01.nyt.com/images/2017/02/26/magazine/26machines/26mag-26machines-t_CA0-facebookJumbo.jpg", "site_section": "", "section_title": "", "url": "https://www.nytimes.com/2017/02/23/magazine/learning-to-love-our-robot-co-workers.html", "country": "US", "domain_rank": 98, "title": "Learning to Love Our Robot Co-Workers - The New York Times", "performance_score": 2, "site": "nytimes.com", "participants_count": 0, "title_full": "Learning to Love Our Robot Co-Workers - The New York Times", "spam_score": 0.014, "site_type": "news", "published": "2017-02-23T12:00:00.000+02:00", "replies_count": 0, "uuid": "55978df7fe85d4e8aa2e392cc2154f259c26abc9"}, "author": "Kim Tingley", "url": "https://www.nytimes.com/2017/02/23/magazine/learning-to-love-our-robot-co-workers.html", "ord_in_thread": 0, "title": "Learning to Love Our Robot Co-Workers - The New York Times", "locations": [], "entities": {"persons": [{"name": "mcgillivray", "sentiment": "none"}, {"name": "masahiro mori", "sentiment": "none"}, {"name": "james bessen", "sentiment": "none"}, {"name": "frankenstein", "sentiment": "none"}, {"name": "donald trump", "sentiment": "none"}, {"name": "julie shah", "sentiment": "none"}, {"name": "carl frey", "sentiment": "none"}, {"name": "norbert wiener", "sentiment": "none"}, {"name": "mori", "sentiment": "none"}, {"name": "karel capek", "sentiment": "none"}, {"name": "jeremy rifkin", "sentiment": "none"}, {"name": "martin luther king jr.", "sentiment": "none"}, {"name": "david mindell", "sentiment": "none"}, {"name": "michael osborne", "sentiment": "none"}], "locations": [{"name": "mich.", "sentiment": "none"}, {"name": "united states", "sentiment": "none"}, {"name": "west", "sentiment": "none"}, {"name": "korea", "sentiment": "none"}, {"name": "hiroshima", "sentiment": "none"}, {"name": "g.m.", "sentiment": "none"}, {"name": "lake orion", "sentiment": "none"}, {"name": "detroit", "sentiment": "none"}, {"name": "america", "sentiment": "none"}, {"name": "singapore", "sentiment": "none"}, {"name": "michigan", "sentiment": "none"}, {"name": "nagasaki", "sentiment": "none"}, {"name": "pennsylvania", "sentiment": "none"}, {"name": "japan", "sentiment": "none"}, {"name": "china", "sentiment": "none"}, {"name": "ohio", "sentiment": "none"}], "organizations": [{"name": "new york times continue", "sentiment": "neutral"}, {"name": "university of oxford", "sentiment": "none"}, {"name": "fanuc", "sentiment": "none"}, {"name": "general motors", "sentiment": "none"}, {"name": "fuji automated numerical control", "sentiment": "none"}, {"name": "kiva systems", "sentiment": "none"}, {"name": "general motors automotive assembly", "sentiment": "none"}, {"name": "university of washington", "sentiment": "none"}, {"name": "m.i.t", "sentiment": "none"}, {"name": "new york times", "sentiment": "none"}, {"name": "lake orion", "sentiment": "none"}, {"name": "m.i.t.", "sentiment": "none"}, {"name": "international organization for standardization", "sentiment": "none"}, {"name": "chevy sonics", "sentiment": "none"}, {"name": "mckinsey global institute", "sentiment": "none"}, {"name": "interactive robotics group", "sentiment": "none"}, {"name": "boston university", "sentiment": "none"}, {"name": "amazon", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "Continue reading the main story Now, as we watched, the operator inserted two tubes into a frame and put it on a rack. The robot, which had a sensor and a magnetic pad attached to its end, tapped the frame with its pad to pick it up, pivoted and gently placed the frame on a mold inside the press. Then it cocked its wrist and nudged a button with one of the pad’s corners. A wheel inside the press spun like a lazy susan, 180 degrees, positioning the mold beneath the nozzle and bringing around a second mold with a frame of cooled catheters. Next the robot lifted this frame and moved it to a trimmer that ejected the catheters. Finally, it stacked the empty frame beside the operator. The cycle took 35 seconds. All the while, the operator examined finished catheters and inserted tubes into frames at a steady but unhurried pace. It wasn’t the robot’s speed that was revolutionary, McGillivray said; other automated machines could do the same things faster. The innovation was its “collaborative” ability: This robot is safe to work with. If it bumps into someone, it stops. (McGillivray, a father of three young daughters whose standards of personal responsibility are marked even by Minnesotan standards, tested this feature on himself first: “Let’s just say it hit a fleshy part of my body, and I didn’t like it. But it didn’t leave a bruise.”) This meant that he didn’t have to build an expensive, semi-permanent safety cage around it. And because the robot is easy to move and reprogram, it can quickly be reassigned to whatever unique processes are required to fill the one-off orders Dynamic typically receives. The robot’s price tag was $35,000, and within two months, it paid for itself by quadrupling the efficiency of the press and eliminating scrap. There was one caveat, though: “Productivity did decrease when we first put the robots in,” McGillivray said, “because they’re so dang fun to watch.” He has since purchased two more of them from Universal Robots, a Danish company, and hired a technician to maintain them. No one was laid off, and the company’s finances are sounder than they have been in nearly 20 years. “I guess I’m kind of an evangelist,” he told me. \nAdvertisement Continue reading the main story “It’s just a machine?” my husband said, when he saw a picture of the arm I had flown a thousand miles to see. “I thought you said it was a robot .” In fact, it was both — a robot is technically just a machine run by a computer — but I knew what he meant because I had gone there with the same expectation. I presumed that the robot would look and act like a human and, consequently, that it would make me and the people who worked with it a little uncomfortable. The more I talked with engineers and civilians alike, the more I came to believe that this feeling was hardly unusual and that it went beyond the perfectly rational fear that a robot might take your job. “My deep worry is that every time you see a robot doing what a human does, there’s this visceral response — it’s human nature,” Julie Shah, a professor of aeronautics and astronautics at M.I.T. and the leader of its Interactive Robotics Group, told me. This response is so intense, and so crucial to people’s acceptance or rejection of robots, that Masahiro Mori, a Japanese robotics professor, famously graphed it in 1970. He found that our affinity for robots increases as they come to look more and more human — until the point when the likeness is similar enough to momentarily fool the eye. Once the illusion is discovered, the viewer is unsettled and affinity plunges, a dip Mori dubbed “the uncanny valley.” The danger is that our uneasiness will prevent us from preparing for a future in which robots interact with humans in increasingly sophisticated ways, and one that — thanks to rapid advances in computing and mechanical engineering — is coming, and coming soon. Much of the current political upheaval in the United States and other Western democracies can be traced to how threatened we feel when faced with this future. Central to Donald Trump’s presidential campaign, and presumably to his victories in manufacturing states like Michigan, Ohio and Pennsylvania, was his promise to bring back the 10 percent of factory jobs that have disappeared in the wake of the Great Recession. But the fact is, American manufacturers are producing more products now than they were before the crash, with fewer workers, which suggests that those missing jobs have been automated. And while collaborative robots are showing up on factory floors first — where automation has always debuted, taking on repetitive, heavy and hazardous work — they are likely to find their way into other workplaces soon. (The “collaborative” label, widely used to imply coexistence, is a bit misleading; robots that can learn, problem-solve and simulate human emotion are still confined mostly to laboratories.) Already, surgical robots make it possible via remote control to perform low-risk operations in outpatient settings; robot home-health aids may soon help people with limited mobility get out of bed, cook meals and perform other routine tasks; and driverless vehicles are poised to take over the transportation and trucking industries. It doesn’t take much imagination to see how similar algorithms, or operating instructions, could enable robots to do many of the tasks required of waiters, maids and hospital workers. A few years ago, Amazon purchased Kiva Systems, which coordinates warehouse robots whose job is to move heavy boxes to stations where human stockers, whose fine motor skills have yet to be affordably mechanized, transfer the boxes to shelves. “We’re moving into an era where people and infrastructure are in a more fluid relationship,” says David Mindell, a professor of aerospace engineering and the history of technology at M.I.T. The question is who will reap the economic rewards of that change. “We tend to think that automation, generally speaking, replaces humans, but really in the big picture that isn’t true,” James Bessen, an economist at Boston University, told me. Instead, it makes goods cheaper, increasing demand and creating more jobs. Only when a product or service becomes so cheap and ubiquitous that lowering its price can’t get people to buy any more of it does automation result in significant unemployment — unless the displaced workers are absorbed by a growing market for a different product or service, or the labor force shrinks. Collaborative robots, designed to fill flexible roles and be smaller and easier to integrate among employees and existing machines, may have a subtler effect, raising the need for more nuanced measures of their socioeconomic impact. In one recent study, Carl Frey and Michael Osborne of the University of Oxford broke down 702 occupations in the United States in detail and analyzed the probability that they would be computerized. Nearly half of those jobs were found to have a “high risk” of being automated within the next few decades. Telemarketers, accountants, retail salespeople, technical writers and real estate agents would be first; chemical engineers, clergy, athletic trainers and dentists last. Conversely, a new McKinsey Global Institute report argues that we should stop considering “entire occupations” and instead focus on “individual activities.” A server must deliver and clear plates (tasks a robot might take over), but he or she also observes diners and anticipates their needs (tasks at which people are still far superior). From this perspective, fewer than 5 percent of careers can be completely automated using existing technology — but “about half of all the activities people are paid to do in the world’s work force could potentially be.” In the West, Frankenstein’s monster embodies the threat of cutting-edge technology. We adopted the word “robot” from a popular 1921 play by the Czech writer Karel Capek about a factory that turns out robots, from robota , a Czech word for forced labor, who rise up and exterminate humanity. But the citizens of Singapore, Korea and Japan, the world’s leading users of industrial robots, and China, the most rapidly growing market for them, generally don’t share the same anxieties. In the Japanese canon, new technology often arrives as weaponry that Japanese scientists turn against an aggressor. (The nuclear parable of “Tetsuwan Atom,” a 1960s TV show about a heroic Japanese robot with an “atomic” heart, was lost in translation when it arrived in America as “Astro Boy.”) Viewing them through a different cultural lens, might we expect collaborative robots to augment a person’s skills, increasing his or her productivity — and thus value — without ruining any lives? Could we look forward to programming these machines to make our jobs better without fear of them usurping us? Or is it naïve to imagine that, if we cooperate with the robots, there won’t come a day when they can do everything we can do, only better, and their owners become our masters? Ever since the invention of the transistor in 1947 started the transformation of computing — just a couple of years after the United States destroyed Hiroshima and Nagasaki with atomic bombs — philosophers have anticipated a day when intelligent machines would do all our work for us. Some pictured a dystopia like the one Jeremy Rifkin described in his 1995 book, “The End of Work”: “Like a deadly epidemic inexorably working its way through the marketplace, the strange, seemingly inexplicable new economic disease spreads, destroying lives and destabilizing whole communities in its wake.” Others envisioned a society in which profits were distributed evenly in the form of a basic income, leaving people to spend their time as they pleased. The Rev. Dr. Martin Luther King Jr., in his final sermon, exhorted his congregation toward this idyll of equality and freedom. “Yes, we do live in a period where changes are taking place,” he said, naming “automation and cybernation” among them. “And there is still the voice crying through the vista of time saying, ‘Behold, I make all things new; former things are passed away.’ ” \nAdvertisement Continue reading the main story Still others believed both scenarios were equally plausible and the outcome would depend upon how judiciously we regulated new technologies, nuclear fission being a powerful example, so that they reduced, rather than increased, human suffering. Chief among them was Norbert Wiener, a mathematics professor at M.I.T., who coined the term “cybernetics” to describe the study of the relationship between living beings and robots. “We can be humble and live a good life with the aid of machines,” he wrote, “or we can be arrogant and die.” Anyone wishing to cross the threshold of the General Motors automotive assembly plant in Lake Orion, Mich., just outside Detroit, must sit in the lobby and watch a safety video. From a TV mounted in a corner above a realistic-looking ficus tree, a pleasant female voice details all the possible things inside that could hurt you: loud noises, flying objects, sharp metal, molten metal, falls from high places and collisions with mobile equipment. It’s both a testament to one of the main applications for collaborative industrial robots — to take over dangerous work from people and to be less dangerous to work with — and an illustration of the difficulties inherent in getting them to do and be so. The physical world presents robots with challenges that most toddlers navigate with ease: selecting a Lego from a bin, falling over and standing back up. The foundation of computing, transistors, are made of hard, rigid silicon, a substance at odds with the soft, flexible contours of our bodies — and the world we’ve designed to conform to them. “I’m just teaching robots how to pick up stuff, and I think it brings to light how much we take for granted about these things,” says Siddhartha Srinivasa, a computer-science and engineering professor at the University of Washington, who designs robots to help people with spinal-cord injuries navigate everyday environments. “When you make coffee or you pick up something, you’re performing these beautiful intricate maneuvers.” The collaborative robots entering manufacturing today are not doing anything nearly as elaborate. In fact, much of the technology they use is decades old. What’s new is the conviction that they are safe, a position largely cemented in 2011, when the International Organization for Standardization added new language to its industrial-safety guidelines to address their implementation. Soon afterward, General Motors and its partner Fanuc (Fuji Automated Numerical Control), a Japanese robotics company whose American headquarters is a few miles from Lake Orion, initiated their first collaborative-robot project. At 4.3 million square feet, Lake Orion is one of G.M.’s smaller plants and the only one in the United States efficient enough to produce compact cars, for which profit margins are much thinner than those of larger vehicles. Overhead, candy-colored Chevy Sonics and electric Bolt EVs travel in cages hanging from tracks near the ceiling as if en route up a ski slope. Their serene pace belies both the bodily risks posed by large moving objects that are insensitive to obstacles and the disaster lurking within all such circuits: a short anywhere along the line that decommissions the whole. On an assembly line turning out a $50,000 vehicle every minute, for instance, six hours of “unscheduled downtime” for repairs represents a potential loss of $18 million. A major benefit of Fanuc’s robots, 30,000 of which are already working in G.M. plants noncollaboratively, is that 8,000 of them are linked to the internet via cloud computing, so engineers can monitor their health and recommend preventive maintenance. Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. Sign Up Receive occasional updates and special offers for The New York Times's products and services. Thank you for subscribing. An error has occurred. Please try again later. You are already subscribed to this email. ", "external_links": [], "published": "2017-02-23T12:00:00.000+02:00", "crawled": "2017-02-23T12:08:44.714+02:00", "highlightTitle": ""}