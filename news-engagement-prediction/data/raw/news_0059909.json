{"organizations": [], "uuid": "00c71da360fb941230b1b3840c25148c67bd5434", "thread": {"social": {"gplus": {"shares": 5}, "pinterest": {"shares": 0}, "vk": {"shares": 3}, "linkedin": {"shares": 3}, "facebook": {"likes": 463, "shares": 463, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "arxiv.org", "main_image": "", "site_section": "", "section_title": "", "url": "https://arxiv.org/abs/1702.06230", "country": "US", "domain_rank": 4330, "title": "[1702.06230] Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning", "performance_score": 4, "site": "arxiv.org", "participants_count": 0, "title_full": "[1702.06230] Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning", "spam_score": 0.209, "site_type": "news", "published": "2017-02-23T06:36:00.000+02:00", "replies_count": 0, "uuid": "00c71da360fb941230b1b3840c25148c67bd5434"}, "author": "", "url": "https://arxiv.org/abs/1702.06230", "ord_in_thread": 0, "title": "[1702.06230] Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning", "locations": [], "entities": {"persons": [{"name": "william f. whitney", "sentiment": "negative"}, {"name": "joshua b. tenenbaum", "sentiment": "negative"}, {"name": "vlad firoiu", "sentiment": "negative"}], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "Authors: Vlad Firoiu , William F. Whitney , Joshua B. Tenenbaum (Submitted on 21 Feb 2017) Abstract: There has been a recent explosion in the capabilities of game-playing artificial intelligence. Many classes of RL tasks, from Atari games to motor control to board games, are now solvable by fairly generic algorithms, based on deep learning, that learn to play from experience with minimal knowledge of the specific domain of interest. In this work, we will investigate the performance of these methods on Super Smash Bros. Melee (SSBM), a popular console fighting game. The SSBM environment has complex dynamics and partial observability, making it challenging for human and machine alike. The multi-player aspect poses an additional challenge, as the vast majority of recent advances in RL have focused on single-agent environments. Nonetheless, we will show that it is possible to train agents that are competitive against and even surpass human professionals, a new result for the multi-player video game setting. ", "external_links": [], "published": "2017-02-23T06:36:00.000+02:00", "crawled": "2017-02-23T01:38:24.988+02:00", "highlightTitle": ""}